














/*
trail notes
you've been doing a great job of making each of these a one screen show!

[x]check
[x]integer, text convert
[x]data, text convert
[x]string clip to parse
[x]string validation, like only alphanumeric, regex from chatgpt
[x]randbetween, inclusive, just in case you need it
[x]ticks to nice text for the user in the current time zone, see if you can avoid a library actually--yes, you can avoid a library and do all the internationalization you need, and very succinctly
[x]say four digit byte size, don't otherwise internationalize numbers

[x]browser crypto, symmetric and asymetric, []hashing
[~]uri encoding, get taht in here just for compleness, have tests that show one+space or one%20space
[]email validation, another one for chatgpt, 1raw, 2cleaned for use, 3normalized for duplicate detection

do all the text checking you need for the database
and for validating single-line user input, like a screen name
not, at this time, the text checking for a user writing a comment


*/



/*
you want to use tag and now as local variables in code
but they're clashing with tag() and now() as short commonly imported functions

you were thinking makeTag(), but tickNow() is not awesome
maybe Tag() and Now()



*/





once you've figured out pinia, you might code the sorted record thing
allows immediate lookups by tag
and also browsing in tick count order
keeps sorted
fast for adding already sorted input data
doesn't readmit duplicates, which will be super common
or maybe pinia already has something better
or maybe this isn't the right way to do things



/*
TODO be able to manually run all the tests these places:
[x]icarus, vite
[]nuxt, local, client-side
[]nuxt, local, server-side, emulated worker
[]nuxt, deployed, client-side
[]nuxt, deployed, server-side, deployed worker
[]lambda, local, server-side, emulated lambda
[]lambda, deployed, server-side, deployed lambda
*/























//maybe wrap json parse and stringify to deal with errors you've encountered





//    _                 
//   (_)___  ___  _ __  
//   | / __|/ _ \| '_ \ 
//   | \__ \ (_) | | | |
//  _/ |___/\___/|_| |_|
// |__/                 

export function jsonStringify(o) {//watch out for a circular reference
	/*
//watch out for a circular reference
try {
return JSON.stringify(o, null)//single line
} catch (e) { return '(circular reference)' }//watch out for circular references
*/
}

export function jsonParse(s) {//watch out for a blank body
	/*
//watch out for a blank body
//get the text first, and keep that, too

r.responseText = await response.text()//might be nothing, even on success
if (r.responseText) r.responseData = JSON.parse(r.responseText)//throws if you give it nothing
*/

}



























/*
2024apr26
code encoding, some bikeshedding

[x]from separate project entry point, Ctrl+S leads to green or red check on page

library0 ~

[]base16 data
[]base64 data
[]base62 data, your code
[]base62 integer, chatGPT's code

[]round trip check
[]toss on failure
[]speed test your base62 with the browser's base64

library1 ~

[]random 1-9
[]random 0-9
[]random 0-9 A-Z a-z

not in scope for this first pass:
-page rendered width analysis
-unicode search for narrow accents that still render
-unified chinese base256





*/







/*

2014may17 hopefully good thinking on finishing off this bike shed

inspect
if you want to inspect an object directly, and y ou know you're in the browser inspector, just use console.log directly
your function inspect() is new, replaces lots of old stuff, and works like this
doesn't log anything, always returns a string
string is always indented, never tries to be single line
doesn't return a tick count, obviously
better than json stringify and node util inspect, actually gets the functions and stuff those miss
always indents by two spaces
goes deep, stopping at 2k of text output
uses 7 number, true boolean, "string", [array], {object}, function()
if you want to see the name of an object, you have to wrap like inspect({object})
test with exception objects
you're going to use inspect to see what third party rest apis are telling your worker

log
starts with timestamp and tilde
logs to record and console.log
turns everything into text, always, using say
keeps everything on one line, always
doesn't call inspect, ever--you have to call that manually

say
turns directly into text, succicently--inspect is the verbose and deep one







*/
















/*
2024may16
dustiest corner of the bike shed
make sure your log and see plan is good before you go back in there
-get rid of log destinations
-do program an indented deep object sayer
-dont use it when there's a browser inspector which has arrows




*/




/*
more bikeshedding here, but what if log worked like this
log(a)
turns a into text, and prefixes it with the timestamp
log(a, b)
not sure anymore
the thing you forgot when designing this refactor above was that in the browser, you don't want everything text, because the browser inspector has arrows to go deep into nested objects, which you won't code yourself, and which is incredible




*/


/*
moar notes and ideas

instead of see doing lines like
(string) s "hello"
all you need is "hello" because quotes mean string
{object}
[array]
"string"
7 with no punctuation is a number
true with no punctuation is a boolean


you made the separte vite entry point
but now nuxt localhost:3000/test is working so well you don't need it(?)
like, it's just as fast
and you can Ctrl+S library0.js several times in a row and it refreshes each time
and, the text stays in place on the page, and also scrolls down in the console
so, what more is there to do here?
i guess refactor it so you don't have log destinations anymore

*/






/*
TODO
see is too confusing; your planned replacement will be called inspect
so then the core functions are log, say, and inspect
*/
/*
export function see(...a) {//see into things, including key name, type, and value
	let s = ''
	for (let i = 0; i < a.length; i++) {
		s += (a.length > 1 ? newline : '') + _see2(a[i])//put multiple arguments on separate lines
	}
	return s
}
function _see2(o) {
	let s = ''
	if (o instanceof Error) {
		s = '(error) ' + o.stack//errors have their information here
	} else if (Array.isArray(o)) {
		s = `(array) [${o}]`
	} else if (typeof o == 'object') {
		s += '(object) {'
		let first = true
		for (let k in o) {
			if (!first) { s += ', ' } else { first = false }//separate with commas, but not first
			s += `${k} (${typeof o[k]}) ${_see3(o[k])}`
		}
		s += '}'
	} else {
		s = `(${typeof o}) ${_see3(o)}`
	}
	return s
}
function _see3(o) {
	try {
		return JSON.stringify(o, null)//single line
	} catch (e) { return '(circular reference)' }//watch out for circular references
}
*/




/*
todo, javascript is so wonky it's hard to make a see that lets you easily look inside
here are some possible improvements
get things on multiple lines and indent them 2 spaces
there's lots of:

ok (boolean) true
n (number) 7
responseText (string) ""
clone (function) undefined
o (object) {message (string) "hello"...}
a (array) [1,2,3]

shorten this so it's just:

ok: true,
n: 7,
responseText: "",
clone(),
o {
	message: "hello"
	...
},
a [1,2,3]

because json stringify skips functions, you'll probably have to write your own recursive walker and indenter
and that's fine, go three levels deep by default

moar notes for your return to this bike shed:

remove look(o), instead you have to call log(see(o))

remove the multiple loggers feature
you want icarus, but will do that later as a separate system
that system will have auto refresh
in-place traffic lights
and an in-place log that is maybe icarus()

you just remembered that log shouldn't turn everything into a string
doing so breaks the inspector's > arrow
this may also be why earlier log didn't tickstamp
if log gets a single string, do it all on one line
if log gets a single non-string, or multiple anything, call console.log multiple times for multiple lines
*/








do encoding at the same time as you do cryptography
maybe make a little object so you dont have to type Uint8array over and over again
the object is indelible
holds some binary data
and has methods to convert between all these different formats:

text, like a string of cleartext
length, how long is it in bytes when you look at it as bytes
base16
base64, checking roundtrips and whatnot

you create these from:
text strings
base16
base64
random data, cryptographically secure

following hte model, this should be tiny, it shouldn't be your node project's Data object



remind yourself of the pattern, but you think you remember it
and now you can use const!

export function Data(c) {
	const o = {}
	o.type = 'Data'//no how do you make that const?
	const type 
	

	const function fromText(s) {

	}

	const function base16()
	const function text()

	return o
}
this constructor makes a new data object

have it lazily create and then save the different forms
understand how utf8 text encoding plays a role with all this, bake that into Data as the default









server logs
dog() and log() goes to datadog
or, figure out your pattern for an api function
with a total covereage try catch
and then maybe if there's an error, inspect it into text and send it back to the browser
and even use status codes, maybe--ask chatgpt
first just see if you can get a stack trace from a worker
but then you have to make sure this isn't an attack vector, you have to know if you're built for production or not

the api full catch also dogs if it takes longer than 2s

a little clock appears in the page at 2s indicating (clock) working 2s...

dog is great because it's secure and private even in deployment--if the attacker figures out how to break an api, they can't get information mistakingly included in a log

duh the workign clock can totally be completely client-side
ask chatgpt if there's a convention in nuxt to guard against repeat requests to the same api
the don't click or you'll mess up your order, thing

ask chatgpt about the confirm form resubmission browser warning
you don't think you're coding any forms that could cause this, but understand it for the first time ever to be sure









/*
this one is for birthdates, stored in the database as text like "1980-02-14"
take the user's input free-form
allow months as feb, 2, 02, whatever
allow years 02, 2002, 76, whatever
figure out what they may mean and put up one or more buttons that snap to

you also need to take a well formatted one, and return the year, month, day as numbers

Date of birth
You must be 18+
Enter like YYYYMMDD four digit year, two digit month, two digit day
Tell us your real birthday!
Not posted on profile, kept private and secure
We check IDs for creators, date must match
Got that as January 22, 1999

If you become a creator
Must match your birthdate on your ID
Private, secure, not posted on profile
We won't post on profile
Must match your ID
Kept private from fans and collaborators
It'll
Birthday with 
that's February 14, 1980


have icarus have a little expandable text box where you can live type into a function to test it



idea for how to get dates the fastest
worst, by the way, is putting up a calendar clicker for today, asking for a dob
phone puts up number pad
instruction text says birthday, YYYYMMDD
see if you can infer other orders, including shorter orders like 040176
if they type YYMMDD, YYYYDDMM
one or two buttons pop up that say "do you mean 2002 Jan 26"
if it's ambiguous, multiple buttons pop up
a single backspace clears the whole field, maybe
*/







/*
//here's a bike shed--write a tight little deindent


so you can
{
	{
		s = `
		first list
		second line
		third line
		`
	}
}

and what you get is
`first line
second line
third line
`

so it removes the leading newline
keeps the other newlines the same
and removes whatever space is at the start of the first line
from all the other lines

maybe remove that number of things
like that number of

confirm you don't chop off any nonwhitespace doing this


*/






/*
function f() {

	const alphabet = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';
	let census = {}
	for (let c of alphabet) census[c] = 0

	let duration = 1*Time.second
	let t = now()
	let d, b
	while (now() < t + duration) {
		d = Data({random: randomBetween(1, 32)})
		b = d.base62()
		for (let c of b) census[c]++
	}

	let s = ''
	for (let c of alphabet) s += `\r\n${c}\t${census[c]}`
	log(s)


}
//f()

test(() => {


})
*/







/*
noop(() => {

	//get some random bytes
	let b16 = Data({random: 40}).base16()
	//encode into base62
	let b62 = arrayToBase62(Data({base16: b16}).array())
	//and back again
	let b16a = Data({array: base62ToArray(b62)}).base16()
	//log to confirm looks good
	log(b62, b16, b16a)


})


noop(() => {

	let d = Data({random: 40})
	let b62 = _arrayToBase62(d.array())
	log(
		b62,
		d.base16(),
		Data({array: _base62ToArray1(b62)}).base16(),
		Data({array: _base62ToArray2(b62)}).base16()
	)


})


/*
async function f() {
	let d, s
	let size = 50
	let duration = 4*Time.second


	let r1 = 0
	let t = now()
	while (now() < t + duration) {
		d = Data({random: size})
		s = arrayToBase64(d.array())
		base64ToArray(s)
		r1++
	}
	log(r1+' base64')

	let r2 = 0
	t = now()
	while (now() < t + duration) {
		d = Data({random: size})
		s = _arrayToBase62(d.array())
		_base62ToArray1(s)
		r2++
	}
	log(r2+' base62 to array method 1')

	let r3 = 0
	t = now()
	while (now() < t + duration) {
		d = Data({random: size})
		s = _arrayToBase62(d.array())
		_base62ToArray2(s)
		r3++
	}
	log(r3+' base62 to array method 2')
}
f()
*/








/*
async function f2() {
	let k = await symmetricCreateKey()
	let b = await symmetricExportKey(k)
	let k2 = await symmetricImportKey(b)
	let p = 'a short message, like card info'
	let c = await encrypt(p, k)
	let d = await decrypt(c, k)
	if (d != p) log('decryption mismatch')
}
async function f3() {
	let k = await createKey_new()
	let b = await exportKey_new(k)
	let k2 = await importKey_new(b)
	let p = 'a short message, like card info'
	let c = await encrypt_new(p, k)
	let d = await decrypt_new(c, k)
	if (d.text() != p) log('decryption mismatch')
}
async function f() {
	log('just in a function f')
	let r1 = 0
	let t = now()
	while (now() < t + 4*Time.second) {
		r1++
	}
	log(r1+' empty')
	let r2 = 0
	t = now()
	while (now() < t + 4*Time.second) {
		await f2()
		r2++
	}
	log(r2+' direct')
	let r3 = 0
	t = now()
	while (now() < t + 4*Time.second) {
		await f3()
		r3++
	}
	log(r3+' custom')
}
f()
*/



/*
improve tiny tests

TODO make this an object that fills up here
but which is exported, and you can bring into a vue component
and run tests there and see results

also, get tests to await async tests etc correctly
this should be pretty easy

also, did you have mustThrow or something before? you need that again; right now you're just skipping writing tests of check* functions

and have it return an object of stats and outcomes, one of which is the composed status line
*/





/*
for inspect()
TODO never add these additional features, because this bike shed is fancy enough:
-recurse, indenting two spaces, stopping if the text grows above 2kb
-deal with tabs and newlines in function definitions and the error stack trace
-show short arrays and objects on a single line; long ones on multiple indented lines
-say the length of a very long array, showing starting and ending items with an ellipsis in the middle

short notes relevant to those never-do improvements
stack trace lines start with four spaces, maybe just remove them
spaces and tabs in function code come through, maybe trim them and separate with the pilcrow
*/
test(() => {
	//early inspect practice
	/*
	let b = true
	let s = 'hello'
	let n = 721
	let a = ["p", "q", "r"]
	let o = {
		name: 'apple',
		quantity: 11,
		f: (()=>{}),
		below: {
			block: 'bedrock'
		}
	}
	let e = (() => {
		let o = {}
		try {
			o.notThere.andBeyond
		} catch (e) {
			return e
		}
	})()
	log(inspect(b, s, n, a, o, e))
	log(inspect(b, s, {n, a, o, e}))
	*/
})
test(() => {
	//more recent inspect practice
	/*
	log(inspect(true))//boolean
	log(inspect(7))//number
	log(inspect('hello'))//string
	log(inspect(['a', 'b', 'c']))//array
	log(inspect({key1: 'value1', key2: 'value2'}))//object

	let f1 = function namedFunction() {
		let i = 7
		return 'named function result'
	}
	let f2 = function() { return 'anonymous function result' }
	log(inspect(f1))//function
	log(inspect(f2))//function

	try {
		notDefined
	} catch (e) {
		log(inspect(e))//error with stack trace
	}
	*/
})




TODO do you need soft versions of the text functions?

//TODO these throw if anything is out of bounds, maybe add startSoft, endSoft, beyondSoft that instead return shorter or blank
//bookmark you added this really fast, go through the larger process of actually testing them, and them using them where you need them
export function startSoft(s, n)  { return clipSoft(s, 0, n) }
export function clipSoft(s, i, n) {
	s = s+''//fix everything
	if (!minInt(i)) i = 0
	if (!minInt(n)) n = 0

	if (i     > s.length) i = s.length
	if (i + n > s.length) n = s.length - i

	return clip(s, i, n)
}
test(function() {
	ok(clipSoft('abc', 1, 0) == '')
	ok(clipSoft('abc', 1, 1) == 'b')
	ok(clipSoft('abc', 1, 2) == 'bc')
	ok(clipSoft('abc', 1, 3) == 'bc')
});


/*
TODO
consider this pattern

checkThing - throws if not
isThing - false if not
makeThing - shapes to bring into compliance and returns

then you put all the tests around isThing
and instead of *Soft here, you use isThing when you don't want an exception
*/


//make Process and Fetch that work node or web worker, vue front or back end
const Access = (typeof process != 'undefined' && process.env) ? process.env : import.meta.env
const Fetch = (typeof fetch != 'undefined') ? fetch : (await import('node-fetch')).default




== base32

https://www.npmjs.com/package/base32
sha256 hash values
base16 is double-clickable, always the same length, but quite long
base64 isn't double-clickable, always the same length, short
base62 is double-clickable, not always the same length, short
base32 is double-clickable, always the same length, shorter
you'll store hashes in the database
to make lookups and filters no slower than necessary, use CHAR(30) or whatever
you can add this quickly using the npm module and your existing pattern for the others



/*
exploration with base32 for hashes that can be compact and all the same length

using
https://www.npmjs.com/package/rfc4648
1 million weekly downloads

hmm, does this lift all of Data from library0 to library1?
yeah, probably
or write matching code that does it raw

Sat 11h 33m 22.709s ~ 32 bytes
0238078539448d35f06e7262ac3e4013798947bd6d5c91e44a35caa25f80224f ~ 64 base16 characters
AI4APBJZISGTL4DOOJRKYPSACN4YSR55NVOJDZCKGXFKEX4AEJHQ ~ 52 base16 characters
1Yj7WJa4YJNlRc9Xg3w14ub9GyskN97ZHYNAdaij29F ~ 43 base62 characters
AjgHhTlEjTXwbnJirD5AE3mJR71tXJHkSjXKol+AIk8= ~ 44 base64 characters

Sat 11h 33m 45.634s ~ 32 bytes
a4508d240c5002106a07e935f3f023060bac03c5daa9e81f078c9eda23f70f3f ~ 64 base16 characters
URII2JAMKABBA2QH5E27H4BDAYF2YA6F3KU6QHYHRSPNUI7XB47Q==== ~ 56 base16 characters
e52D91oI1W0f0ieDVFl8lOBg1F5tfcd7lUCckdYiSFFl ~ 44 base62 characters
pFCNJAxQAhBqB+k18/AjBgusA8XaqegfB4ye2iP3Dz8= ~ 44 base164characters

ok, difficulties include:
this would elevate data to library1, or require some complex injection pattern
padding should be there, really, and is super long for 32 bytes
even without, really not that much shorter than base16
and base16 makes it look like a hash value
so, don't add base32, and use base16 and CHAR(64) in the database for hash values
*/
import { base32 } from 'rfc4648'
test(() => {
	let d = Data({random: 32})//sha256 hash value
	let b32 = base32.stringify(d.array(), {pad: true})

log(`${d.size()} bytes
${d.base16()} ~ ${d.base16().length} base16 characters
${b32} ~ ${b32.length} base16 characters
${d.base62()} ~ ${d.base62().length} base62 characters
${d.base64()} ~ ${d.base64().length} base64 characters`)
})







== browser fingerprint

the browser key in local stroage can keep the user signed in forever
but, an attacker could coach a n00b through discord to share it with him
so also use a browser fingerprint
you're looking for something script can't affect, and which doesn't change
even as the device moves geographically and goes through browser and os updates

WebGL Renderer: NVIDIA GeForce GTX 1050 Ti/PCIe/SSE2
WebGL Vendor: NVIDIA Corporation
User Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36
Screen Resolution: 1920x1080

don't do screen resolution because multiple monitors and turning your phone
add window.location to get https://cold3.cc, make sure there's not a page afterwards
and add the browser tag
so you're hashing text like this:

agent:Mozilla/. (Macintosh; Intel Mac OS X __) AppleWebKit/. (KHTML, like Gecko) Chrome/... Safari/.;renderer:NVIDIA GeForce GTX 1050 Ti/PCIe/SSE2;vendor:NVIDIA Corporation;tag:lYPvabMNWoWwlrgkguy0g;

you make and save tag if it's not already there before doing this
you never send tag over the wire, just the hash
you never save that hash to disk, just the wire
yeah, this is a great idea
keep the user signed in forever, (unless he upgrades his video card)
but also make it so a reddit coach can't get a n00b victim to look in local storage and share his browser tag

maybe even call it
account-access-tag-DO-NOT-SHARE

current_session_password: account_access_code_DO_NOT_SHARE_lYPvabMNWoWwlrgkguy0g

what if you did that, except for user agent, you remove all the numerals

also, save it in a global variable so you only have to hash it once on page load, not every time you make a request

async function getBrowserFingerprint() {
  // Get WebGL Renderer and Vendor
  const getWebGLFingerprint = () => {
    const canvas = document.createElement('canvas');
    const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
    if (!gl) return null;

    const debugInfo = gl.getExtension('WEBGL_debug_renderer_info');
    if (!debugInfo) return null;

    const renderer = gl.getParameter(debugInfo.UNMASKED_RENDERER_WEBGL);
    const vendor = gl.getParameter(debugInfo.UNMASKED_VENDOR_WEBGL);

    return {
      renderer: renderer,
      vendor: vendor
    };
  };

  // Get User Agent
  const userAgent = navigator.userAgent;

  // Get Screen Resolution
  const screenResolution = `${screen.width}x${screen.height}`;

  // Combine all pieces of information
  const webGLFingerprint = getWebGLFingerprint();
  if (!webGLFingerprint) return "WebGL information not available";

  const combinedFingerprint = `
    WebGL Renderer: ${webGLFingerprint.renderer}
    WebGL Vendor: ${webGLFingerprint.vendor}
    User Agent: ${userAgent}
    Screen Resolution: ${screenResolution}
  `;

  return combinedFingerprint.trim();
}

// Example usage
getBrowserFingerprint().then(fingerprint => {
  console.log(fingerprint);
});











== moar web security, CORS

net23 apis will check the origin header right in the lambda node code
you should also make cold3.cc/api apis only talk to cold3.cc and net23 on https
you could check origin in code, but a more standard way is to implement the CORS preflight thing
and a standard way to do that is:
https://nuxt-security.vercel.app/documentation/middleware/cors-handler
"Testing CORS configuration can be done by running one application with NuxtSecurity enabled and creating a second application (that is running on a different port) that will send a request to the first app. Then, a CORS error could be easily observed that proves that CORS is working as expected."

if you've got things all CORS-ed up, can you still develop on localhost?






== moar web security, CSP

chatgpt suggests:

<head>
  <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self'; style-src 'self'; object-src 'none'; frame-ancestors 'none'">
</head>

but not sure what this prevents. not injecting script directly into the page through inspector, but maybe a chrome extension running script?
also not sure what adding this could break








== iphone faceid for the web

for four years now you've been able to do faceid on the web!
but you've never seen it anywhere!
and, it's easy!

https://developer.apple.com/videos/play/wwdc2020/10670/
https://webkit.org/blog/11312/meet-face-id-and-touch-id-for-the-web/
https://support.apple.com/en-us/HT213449

const options = {
    publicKey: {
        rp: { name: "example.com" },
        user: {
            name: "john.appleseed@example.com",
            id: userIdBuffer,
            displayName: "John Appleseed"
        },
        pubKeyCredParams: [ { type: "public-key", alg: -7 } ],
        challenge: challengeBuffer,
        authenticatorSelection: { authenticatorAttachment: "platform" }
    }
};
const publicKeyCredential = await navigator.credentials.create(options);

Registration (Face ID Setup)
-The user clicks the "Register Face ID" button.
-A new credential is created using navigator.credentials.create().
-The options include information about the relying party (your website), the user, and the desired credential parameters.
-The public key credential is logged and should be sent to your server for storage.

Authentication (Using Face ID)
-The user clicks the "Authenticate with Face ID" button.
-The user's Face ID is authenticated using navigator.credentials.get().
-The options include a challenge and the allowed credentials (user's registered credential ID).
-The assertion is logged and should be sent to your server for verification.






== four similar but distinct tasks

1 logs for development (logflare)
only use while coding
console.log works great locally, but not pushed
confirm that you're getting the same error both places
doesn't need to be permanent
needs to be absolutely reliable and instantaneous

2 logs for production (datadog)
use in production
keep a permanent record of all the details that happened with every third party api
do more analysis later, asking questions then you haven't though of now

3 uptime checking (pingdom, datadog synthetics, checkly)
know if cloudflare pages, workers, lambda, or supabase goes down or becomes slow
be on pagerduty to confirm and complain
if there's an outage in the middle of the night, know how long it lasted, and how frequently this happens

4 round robin control, api performance, and fault alerting (kinesis, datadog, kafka)
balance load between two equivalent third party apis, like for sending SMS, or charging credit cards
immediately stop using a service that starts rejecting use, or no users can complete tasks on
use for third party services that are easy to stack redundantly and likely to break or be unreliable
see a dashboard of median response time and processing time of api calls and database queries

and you started into kinesis by saying imagine you're sending it a stream of numbers, and want the hourly average

https://docs.aws.amazon.com/msk/latest/developerguide/serverless.html
is fast, serverless, and lets you query by timestamp range (kinesis just lets you look at the last 5mb or whatever)

>next morning thinking

[0] logs for development
use logflare, it's simple and faster than datadog

[1] downtime and pagerduty for pages, workers, and supabase
a provider like pingdom is setup for sanity checking, is my site online
for having their own dashboard put up a graph for, how fast is page load? hello world api? increment count api? testing cloudflare pages, workers, and supabase speeds
sends you a pagerduty alert (can they do telegram?) if cloudflare pages, workers, or supabase are down
but this doesn't test speeds as encountered by real users, and that's fine, you trust the providers to be good about that

[2] redundant fragile apis like sms, email, credit cards. characteristics:
these have the following properties:
likely to be slow and unreliable
likely to stop working for a day, or forever
easy to place redundant ones in a list and use round-robin
some also have user interaction steps, you only know a sms got through when the user types it in (and can only compare speeds when you've got really a lot of users doing this)

[2b] needs
here, the system needs a few things:
(i) real time knowledge when one breaks, not to tell a human, rather to automatically steer around
(ii) auditable record of everything we told the api, and everything it said back, to use later maybe

[2c] datadog for audit logs
datadog is for historic logs
every api interaction, you dog() everything you told the api, and everything it said back
you don't use this, but it's there for later, if you need it

[2d] sql pattern for round robin visibility
you make a pattern in supabase to track the minute to minute speed and reliability of fragile apis
a table is really simple, just a tick count, a millisecond duration, and success or failure
and then that table is named, like the name of one provider in one category, like aws email, or braintree cards
these tables only hold the last hour or two of data
if something is very rare, it also holds the last 1000 records or whatever
you call it with a function like robin(name, duration, outcome) and it adds a row, finding the right table
you query it with another function, and it tells you the average, median, fastest and slowest N events, and if there are a bunch of recent failures, like it's been broken for 20 minutes and counting, or something
when a call comes in and sees that it's the first call in a short time period (one minute? 6 minutes?) it automatically performs the totalling step
this step involves totalling up everything from the previous time period, storing the computed answers in another table, which has like one row per timeperiod, and then removing the rows about that time period from the granular table

[2e] this is an opportunity to try out another provider alongside supabase, like Neon, to see what the developer experience is like, and maybe it's faster
but, you code this for generic sql just like the regular database
these tables are also different because they drop rows

ok, based on all that, let's snapshot the design concept by looking at javascript function prototypes, and providers

log() - fancied up and sent to console.log
flare() - log to logflare, to see an error once pushed, and then remove it ~ uses logflare
dog() - goes to datadog, to add a note to the audit trail for real data in production ~ uses datadog

robinStart('email', 'amazon', tag) - we've asked aws to send a sms, and local code tracks the request with tag in a local variable
robinBad('email', 'amazon', tag) - some time later, the api denied our request
robinGood('email', 'amazon', tag) - the api and the user succeeded. oh here the tag local variable doesn't work anymore
robinChoose('sms') - returns which one to use, like 'amazon' or 'sendgrid' based on flipping a coin and avoiding errors

oh, there's a page at /staff that shows the performance of all of these
and make it so that to add a new one, you just start talking about it, you don't have to do anything else
because there are like two dozen tables named 001-012, and then an organizer table which holds the names
this is a really cool idea, you can get what you need in just a few screenfuls of code
~ uses supabase or neon/planetscale, one of the others

real pages pingdom and users can go to
/ping1 static page from cloudflare pages
/ping2 page that depends on a hello world cloudflare worker
/ping3 essentially your count button, page->worker->supabase settings table
~ try pingdom, datadog synthetics, and checkly, and see what you like

you're really happy with all of this
notice how much you got done just in .txt, not .js
this also completely avoids kinesis and kafka, which you might have dove into
also, instead of making log() more complex, log(), flare() and dog() are separate and simple this way

actually the robin interface is like this:

robin1 - about to call the api
robin2 - api returned reporting success
robin3 - user completed task proving success
robin4 - api returned refusal or failure

14 - the api hates us now, duration not really important here, "red fourteens"
123 - everything's working for the user, 13 duration is important "green onetwentythrees"
10 - the api never got back to us, really broken "red one nothings"
120 - the api says it worked, but the user never was able to do it or gave up "purple twelve nothings"

current minute - add records
previous minute - wait for users
two minutes ago - total up, but keep around for the daily digest. these three do the real time intelligence

current hour
previous hour
two hours ago - total up and move to archival table, which will grow one record per service per user, which is fine

a single lastcycle tick in the control table notices new minutes and hours, and performs the necessary totaling

more later:

you can totally do this efficiently and easily without sets of tables for provider
there are three tables
robin_control - settings just for robin
robin_hours - finished records of each service each hour, totaled and averaged for 1-2pm at the start of 3pm
robin_minutes - individual recent records

hours counts the 14s, 123s, 1nothing, and 12nothings
the 123s duration is meaningfull, hours includes the mean, median, standard deviation, and specific outliers

columns like:
service
provider
tick1
tick2
tick3
tick4
and then you select to total and average
and select to remove old rows only if there are too many rows

the intelligence to pick a service for a task isn't baked into the robin api, rather it's all in the worker, using that api
functions like robinRecent(service, provider) returns a js object with mean, median, failure rates, and so on
and from those results the business logic in the worker

maybe do to the minute, and then every 6 hour period, quarter day
so the site can be up years and the records don't get very huge
and an api that breaks can be detected really quickly and steered around

all you need to do are: 10, 50, 90th percentile value, those three, 50 is median of course
you don't need average, and you don't need slowest and fastest list






== big divide

some bike shed
fraction([1, 2, 3], [4])
always takes numerator and denomonator arrays, , [1] if you just want to multiply
always takes js numbers, not strings, not bigints
checks that they're all numbers and integers
multiplies top and bottom and then does the division, that part uses bigint so it can go over
throws if the answer is too big to fit as a regular js integer
returns an object of answers which include answer and remainder









